{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb41b92c",
   "metadata": {},
   "source": [
    "# Introduction to Working with Text Data\n",
    "\n",
    "Data Science is a versatile field that integrates techniques from different domains to extract meaningful information from data. Often, the data we work with is numerical, perhaps tabular and structured. However, a significant portion of the data available today is unstructured and in the form of text. This chapter focuses on why and how we work with such text data.\n",
    "\n",
    "Text data can be found in various forms and domains. It's ubiquitous in today's digital world and holds immense value when it comes to generating insights and making informed decisions. In general, we can categorize the applications of text data in data science into two broad categories:\n",
    "\n",
    "## 1. Data and Structures as Strings\n",
    "\n",
    "String data forms a large part of the information we handle in our day-to-day lives and in scientific research. It can include:\n",
    "\n",
    "- **File and Folder names**: These are often encoded as text and carry essential information about the content they represent. Proper management and manipulation of these names can significantly enhance our productivity and efficiency.\n",
    "- **Categorical Data**: Many real-world datasets contain categorical features such as Pokémon type, credit card usage, eye color, etc. These categories are typically represented as text data.\n",
    "- **Names and Designations**: In various fields like social sciences, human resources, and even technical domains, names and designations (for people, products, companies, etc.) are prevalent and crucial.\n",
    "\n",
    "## 2. Human Language in Text Form\n",
    "\n",
    "Much of our communication today happens via written text. Such data is rich and diverse, and its analysis can provide a wealth of insights. It includes:\n",
    "\n",
    "- **Social Media, Emails, Chats**: A substantial amount of information is exchanged through social media posts, emails, and chat conversations. Analyzing this data can help understand user behavior, sentiments, trends, and more.\n",
    "- **News and Press Releases, Print Media**: These sources provide a constant stream of new information about the world. Text analysis on such data can reveal patterns, detect events, and even predict future occurrences.\n",
    "- **The Internet**: The Internet is predominantly text, from information-dense Wikipedia articles to YouTube video tags and titles. Web scraping and text mining can help extract valuable insights from this vast reservoir of data.\n",
    "- **Protocols and Transcripts**: Transcriptions of meetings, court proceedings, and more provide a formal record of events. Analyzing these can reveal decision patterns, biases, and other organizational dynamics.\n",
    "- **Legislative Texts, Manuals**: Legal texts and manuals contain structured and vital information. Text analysis can aid in understanding, summarizing, and even automating parts of these documents.\n",
    "\n",
    "In the following sections of this chapter, we will delve into how we can effectively manage and process these text data to extract valuable insights. This includes techniques from simple string manipulation to advanced natural language processing. Understanding text data and how to work with it is an invaluable skill in the modern data science landscape.\n",
    "\n",
    "But let us start with the most fundamental basics: string handling!\n",
    "Here a simple short text to work with (the text was generated by ChatGPT with its unique sense of humor...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae27008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a far-off land of data, lived a strange yet\n",
      "curious character known as Stringman. Stringman wasn't an ordinary\n",
      "resident of this land. He had a unique ability to transform himself\n",
      "into different forms.\n",
      "\n",
      "One day, String-man decided to visit the 'Tuple Twins'. As he was\n",
      "journeying, he had to pass through the eerie 'List Forest'.\n",
      "Suddenly, a wild 'IndexError' appeared. It was well-known that\n",
      "'IndexErrors' were not fond of anyone from the 'String' family. \n",
      "String man, being clever, quickly transformed into 'string-man'\n",
      "and tricked the 'IndexError' saying, \"You must be mistaken, I am\n",
      "not a Stringman, but a mere hyphenated man.\"\n",
      "\n",
      "Fooled by his disguise, the 'IndexError' let him pass. String-man\n",
      "then continued his journey, relishing his victory over the 'IndexError'\n",
      "and looking forward to meeting the 'Tuple Twins'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_text = \"\"\"Once upon a time, in a far-off land of data, lived a strange yet\n",
    "curious character known as Stringman. Stringman wasn't an ordinary\n",
    "resident of this land. He had a unique ability to transform himself\n",
    "into different forms.\\n\n",
    "One day, String-man decided to visit the 'Tuple Twins'. As he was\n",
    "journeying, he had to pass through the eerie 'List Forest'.\n",
    "Suddenly, a wild 'IndexError' appeared. It was well-known that\n",
    "'IndexErrors' were not fond of anyone from the 'String' family. \n",
    "String man, being clever, quickly transformed into 'string-man'\n",
    "and tricked the 'IndexError' saying, \"You must be mistaken, I am\n",
    "not a Stringman, but a mere hyphenated man.\"\\n\n",
    "Fooled by his disguise, the 'IndexError' let him pass. String-man\n",
    "then continued his journey, relishing his victory over the 'IndexError'\n",
    "and looking forward to meeting the 'Tuple Twins'.\n",
    "\"\"\"\n",
    "\n",
    "print(my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58751f",
   "metadata": {},
   "source": [
    "## Basic Python string handling methods\n",
    "The Python string data type already comes with many basic string handling methods. Here, more as a repetition, some of the most common ones:\n",
    "\n",
    "### Python String Methods\n",
    "|     Method        |     Description                            |\n",
    "|---------------------|---------------------------------------------------------------------------------------------------|\n",
    "|     count()         |     Returns the number of times a specified   value occurs in a string                            |\n",
    "|     encode()        |     Returns an encoded version of the   string                                                    |\n",
    "|     endswith()      |     Returns true if the string ends with   the specified value                                    |\n",
    "|     index()         |     Searches the string for a specified   value and returns the position of where it was found    |\n",
    "|     islower()       |     Returns True if all characters in the   string are lower case                                 |\n",
    "|     isupper()       |     Returns True if all characters in the   string are upper case                                 |\n",
    "|     join()          |     Joins the elements of an iterable to   the end of the string                                  |\n",
    "|     lower()         |     Converts a string into lower case                                                             |\n",
    "|     strip()         |     Returns a trimmed version of the string                                                       |\n",
    "|     lstrip()        |     Returns a left trim version of the   string                                                   |\n",
    "|     replace()       |     Returns a string where a specified   value is replaced with a specified value                 |\n",
    "|     rstrip()        |     Returns a right trim version of the   string                                                  |\n",
    "|     split()         |     Splits the string at the specified   separator, and returns a list                            |\n",
    "|     splitlines()    |     Splits the string at line breaks and   returns a list                                         |\n",
    "|     startswith()    |     Returns true if the string starts with   the specified value                                  |\n",
    "|     strip()         |     Returns a trimmed version of the string                                                       |\n",
    "|     upper()         |     Converts a string into upper case                                                             |\n",
    "\n",
    "\n",
    "This is not a full introduction to basic string handling with Python. For more information, you can easily find plenty of material online, for instance the [w3schools on Python strings](https://www.w3schools.com/python/python_ref_string.asp). Here, we will simply go through a few common examples as a refresher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb6e683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'once upon a time, in a far-off land of data, lived a strange yet\\ncurious character known as stringman. stringman wasn\\'t an ordinary\\nresident of this land. he had a unique ability to transform himself\\ninto different forms.\\n\\none day, string-man decided to visit the \\'tuple twins\\'. as he was\\njourneying, he had to pass through the eerie \\'list forest\\'.\\nsuddenly, a wild \\'indexerror\\' appeared. it was well-known that\\n\\'indexerrors\\' were not fond of anyone from the \\'string\\' family. \\nstring man, being clever, quickly transformed into \\'string-man\\'\\nand tricked the \\'indexerror\\' saying, \"you must be mistaken, i am\\nnot a stringman, but a mere hyphenated man.\"\\n\\nfooled by his disguise, the \\'indexerror\\' let him pass. string-man\\nthen continued his journey, relishing his victory over the \\'indexerror\\'\\nand looking forward to meeting the \\'tuple twins\\'.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748f0cf",
   "metadata": {},
   "source": [
    "One of the first things to note when working with text data in Python is the presence of special character sequences like `\\'` and `\\n`. You might have noticed these appearing in our story about Stringman when we printed the lowercased text using `my_text.lower()`. These are known as escape sequences.\n",
    "\n",
    "The `\\'` sequence is used to include literal single quotes (`'`) in our text string. This is necessary because Python interprets single quotes as marking the start or end of a string. Therefore, to use a single quote as part of the string itself (for instance, in contractions like \"don't\" or to denote possession as in \"Python's\"), we 'escape' it using a backslash (`\\`) before the quote.\n",
    "\n",
    "On the other hand, `\\n` is a newline character that is used to start a new line. Python interprets this sequence as a single character that moves the cursor to the next line. This is why we see the text broken into multiple lines when we print the content of `my_text`.\n",
    "\n",
    "Understanding and being able to handle such escape sequences is an essential part of working with text data, as they can affect the processing and analysis of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb210a2",
   "metadata": {},
   "source": [
    "#### Modify strings\n",
    "A very common method used to modify strings in Python is via the `replace()` methods. This is well suited to replace specific characters or sequences of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9643e14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"W3 don't always l!k3 all charact3rs and s3qu3nc3s w3 hav3.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"We don't always like all characters and sequences we have.\"\n",
    "s.replace(\"i\", \"!\").replace(\"e\", \"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98bcf1",
   "metadata": {},
   "source": [
    "> ### Mini Quiz!\n",
    "> Make a guess: What would the following code return?\n",
    "```python \n",
    "print(\"abc\".replace(\"ab\", \"cc\").replace(\"c\", \"x\"))\n",
    "```\n",
    "> a) ccx  \n",
    "> b) ab  \n",
    "> c) xxx  \n",
    "> d) abx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7ad6d",
   "metadata": {},
   "source": [
    "#### Count words\n",
    "Counting words is a very common task. It is even central to many data science methods. Python string methods include methods like `count()` which, like their name says, can do some of this counting for us. But we will quickly see, that often this is not good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fc6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.count(\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cad796",
   "metadata": {},
   "source": [
    "Careful. This will not count all words \"no\", but every single occurence of the letter sequence `no` in our string, which would also include words like \"none\" or \"nothing\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "130a3c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.count(\"stringman\"), my_text.count(\"string-man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3140315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.lower().count(\"stringman\"), my_text.lower().count(\"string-man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0dccd7",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22b4d7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'upon', 'a', 'time,', 'in', 'a', 'far-off', 'land', 'of', 'data,', 'lived', 'a', 'strange', 'yet\\ncurious', 'character', 'known', 'as', 'stringman.', 'stringman', \"wasn't\", 'an', 'ordinary\\nresident', 'of', 'this', 'land.', 'he', 'had', 'a', 'unique', 'ability', 'to', 'transform', 'himself\\ninto', 'different', 'forms.\\n\\none', 'day,', 'string-man', 'decided', 'to', 'visit']\n"
     ]
    }
   ],
   "source": [
    "words = my_text.lower().split(\" \")  # still many wrong words in there\n",
    "print(words[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "435ddc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'upon', 'a', 'time', 'in', 'a', 'far-off', 'land', 'of', 'data', 'lived', 'a', 'strange', 'yet', 'curious', 'character', 'known', 'as', 'stringman', 'stringman', \"wasn't\", 'an', 'ordinary', 'resident', 'of', 'this', 'land', 'he', 'had', 'a', 'unique', 'ability', 'to', 'transform', 'himself', 'into', 'different', 'forms', '', 'one']\n"
     ]
    }
   ],
   "source": [
    "words = my_text.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"\\n\", \" \").split(\" \")\n",
    "print(words[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980caf1b",
   "metadata": {},
   "source": [
    "### Very common problem: different variations of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04715883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count(\"stringman\"), words.count(\"string-man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "026a9cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stringman', 'stringman', 'stringman']\n"
     ]
    }
   ],
   "source": [
    "variations = [\"string-man\", \"stringman\", \"string man\"]\n",
    "\n",
    "# Solution 1\n",
    "translations = {\"string-man\": \"stringman\",\n",
    "               \"string man\": \"stringman\",\n",
    "               \"stringman\": \"stringman\"}\n",
    "\n",
    "print([translations[w] for w in variations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da6176ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stringman', 'stringman', 'string man']\n"
     ]
    }
   ],
   "source": [
    "# Solution 2 - real bad\n",
    "\n",
    "print([w.replace(\"-\", \"\") for w in variations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865a349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['das', 'wichtigste', 'steht', 'nicht', 'in', 'meinem', 'tweet', 'sondern', 'in', 'den', 'hashtags', '#openscience', '#openaccess', '#research']\n"
     ]
    }
   ],
   "source": [
    "my_text2 = \"Das Wichtigste steht nicht in meinem Tweet sondern in \\\n",
    "den Hashtags #openscience #openaccess #research\"\n",
    "\n",
    "words = my_text2.lower().split(\" \")\n",
    "words = [w.strip(\".,!? \") for w in words]\n",
    "words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84b4298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag: #openscience\n",
      "Hashtag: #openaccess\n",
      "Hashtag: #research\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    if w.startswith(\"#\"):\n",
    "        print(f\"Hashtag: {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34878e9e",
   "metadata": {},
   "source": [
    "## Regular Expressions (Regex)\n",
    "\n",
    "Regular Expressions, often shortened to \"regex,\" are a powerful tool for working with text data. They're a sequence of characters forming a search pattern, primarily used for pattern matching with strings or string manipulation. In the world of Data Science, regular expressions find widespread use in text processing tasks.\n",
    "\n",
    "### What are Regular Expressions?\n",
    "\n",
    "At their core, regular expressions are a means to describe patterns within strings. They offer a flexible and concise way to identify strings of text such as particular words, patterns of characters, or a combination of these. This can be as simple as searching for a specific word or as complicated as extracting all email addresses from a text.\n",
    "\n",
    "### Uses of Regular Expressions\n",
    "\n",
    "Regular expressions are used for several text processing tasks:\n",
    "\n",
    "- **Validation**: They can check if the input data follows a certain format, such as an email address or a telephone number.\n",
    "- **Search**: You can use regex to locate specific strings or substrings within a larger piece of text.\n",
    "- **Substitution**: They can be used to replace certain patterns in a string.\n",
    "- **Splitting**: Regular expressions can define the delimiter to split a larger string into a list of smaller substrings.\n",
    "- **Data Extraction**: They are often used to scrape web data, where specific patterns need to be extracted from HTML code.\n",
    "\n",
    "### Pros and Cons of Regular Expressions\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- **Versatile**: Regular expressions can handle a multitude of string matching problems with concise expressions.\n",
    "- **Portable**: The principles of regular expressions can be applied across many programming languages, command-line tools (like `grep`, `sed`, `awk`), databases, etc.\n",
    "- **Powerful**: Regular expressions can match complex patterns and perform sophisticated string manipulations.\n",
    "\n",
    "#### Cons\n",
    "\n",
    "- **Complexity**: Regular expressions can become complex and hard to understand and maintain, especially for intricate patterns.\n",
    "- **Readability**: A complicated regular expression can be quite cryptic, and lack of standardization in regex flavors can cause compatibility issues.\n",
    "- **Efficiency**: Depending on the complexity, regular expressions might not be the most efficient way to perform string operations, especially for very large text data.\n",
    "\n",
    "### Using Regular Expressions in Python\n",
    "\n",
    "Python's built-in `re` module allows us to use regular expressions ([see documentation](https://docs.python.org/3/library/re.html)). The module provides several functions, including `match()`, `search()`, `findall()`, `split()`, `sub()`, and others, each designed to manipulate strings in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1c4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "search = re.search(r\"string[- ]?man\", my_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9454ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(119, 129), match='string-man'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c50fdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "no such group",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: no such group"
     ]
    }
   ],
   "source": [
    "search.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a7c52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.findall(\"string[- ]?man\", my_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7421c645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['string-man', 'stringman']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2889640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\nmno'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\\nmno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0a6f3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmno'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\nmno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c45b4969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nmno\n",
      "\n",
      "mno\n"
     ]
    }
   ],
   "source": [
    "print(r\"\\nmno\")\n",
    "print(\"\\nmno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbabba",
   "metadata": {},
   "source": [
    "### Text, Numbers, Classes\n",
    "\n",
    "- `.` any character except \"new line\" (\"\\n\")\n",
    "- `\\d` a digit, that is 1, 2, ... 9\n",
    "- `\\D` no digit, i.e., any character except 1, 2, ... 9\n",
    "- `\\w` a word character, which includes lower + upper case letters, digits, and underscore\n",
    "- `\\W` no word character\n",
    "- `\\s` a space or tab character\n",
    "- `\\S` no space or tab character, almost all characters\n",
    "- `[aAbBcC]` any of the contained characters\n",
    "- `[^aAbBcC]` NONE of the contained characters\n",
    "\n",
    "### Positions in the String\n",
    "\n",
    "- `^` beginning of the string\n",
    "- `$` end of the string\n",
    "- `\\b` word boundary\n",
    "\n",
    "### Repetitions\n",
    "\n",
    "- `?` zero or once, i.e., the expression is optional\n",
    "- `+` at least once\n",
    "- `*` any number of times (including none)\n",
    "- `{n}` exactly n times\n",
    "- `{min,max}` at least min times and at most max times\n",
    "- `{min,}` at least min times\n",
    "- `{,max}` at most max times\n",
    "\n",
    "### Characters\n",
    "\n",
    "- `[A-Z]` ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "- `[a-z]` abcdefghijklmnopqrstuvwxyz\n",
    "- `[0-9]` (or `\\d`) 0123456789\n",
    "- `\\w` Word = At least one letter, a digit, or underscore (short for `[a-zA-Z0-9_]`).\n",
    "- `\\W` No word. Short for `[^a-zA-Z0-9_]`\n",
    "- `\\d` Digit (short for `[0-9]`).\n",
    "- `\\D` No digit (short for `[^0-9]`).\n",
    "\n",
    "### Groups and Branches\n",
    "\n",
    "- `|` is an `or` --> `A|B` therefore looks for matches with A or B.\n",
    "- `[]` contains a set of characters. `[abc]` would therefore expect an a, b, or c.\n",
    "- `(...)` denotes a group. This will be given separately later, e.g., when we execute `re.findall()` or `re.search()`.\n",
    "- `(?:...)` is a \"non-capturing group\", i.e., a group that is not given separately later.\n",
    "- `(?=...)`, `(?!...)` \"Positive Lookahead\", \"Negative Lookahead\" describe patterns that must follow. However, these are not read out with.\n",
    "- `(?<=...)`, `(?<!...)` \"Positive Lookbehind\", \"Negative Lookbehind\" describe patterns that must precede. However, these are not read out with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08ff847b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.com', '.de']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiele\n",
    "\n",
    "re.findall(r\"\\.\\w{2,3}\", \"dot.com oder dot.de\")  #Achtung: nicht r\".w...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f2d6816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.de']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\.\\w{2,3}$\", \"dot.com oder dot.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "230a3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nerd_string = \"500GB for 100$ is not so great. \\\n",
    "I want 1000.0 Gigabytes for less than 99.90 $\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14889381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB', 'Gigabytes']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r\"[0-9\\.]+\\s*(GB|[Gg]igabytes)\"\n",
    "re.findall(regex, nerd_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e824c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('500', 'GB'), ('1000.0', 'Gigabytes')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r\"([0-9\\.]+)\\s*(GB|[Gg]igabytes)\"\n",
    "re.findall(regex, nerd_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e98fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awo',\n",
       " 'Frankfurter',\n",
       " 'Vorteilsannahme',\n",
       " 'Landgericht',\n",
       " 'Vorteilsannahme',\n",
       " 'Awo',\n",
       " 'Interessen',\n",
       " 'Awo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Artikel und Nomen finden\n",
    "#regex = r\"(der|die|das)\\s([A-Z][a-z]*)\"\n",
    "#regex = r\"(?:der|die|das)\\s[A-Z][a-z]*\"\n",
    "regex = r\"(?<=der|die|das)\\s([A-Z][a-z]*)\"\n",
    "\n",
    "artikel = \"\"\"\n",
    "FRANKFURT/MAIN dpa | Der Frankfurter Oberbürgermeister Peter Feldmann (SPD) muss sich im Zusammenhang mit der Awo-Affäre vor Gericht verantworten. Eine entsprechende Anklage der Frankfurter Staatsanwaltschaft wegen des Verdachts der Vorteilsannahme wurde zugelassen, wie das Landgericht Frankfurt am Montag mitteilte. Termine für den Prozess standen zunächst noch nicht fest.\n",
    "\n",
    "Die Ermittlungsbehörde hatte im März Anklage wegen eines hinreichenden Tatverdachts der Vorteilsannahme erhoben. Feldmanns Frau habe als Leiterin einer Awo-Kita „ohne sachlichen Grund“ ein übertarifliches Gehalt bezogen, hieß es.\n",
    "\n",
    "Zudem habe die Awo laut Staatsanwaltschaft Feldmann im Wahlkampf 2018 durch Einwerbung von Spenden unterstützt. Im Gegenzug habe er die Interessen der Awo Frankfurt „wohlwollend berücksichtigen“ wollen.\n",
    "\n",
    "Feldmann steht auch wegen einiger Ausrutscher unter Druck – unter anderem wegen eines Videos, das zeigt, wie Feldmann auf dem Flug zum Europa-League-Finale von Eintracht Frankfurt nach Sevilla von Flugbegleiterinnen spricht, „die mich hormonell am Anfang erst mal außer Gefecht gesetzt haben“. Feldmann entschuldigte sich dafür, lehnte einen Rücktritt aber ab.\n",
    "\"\"\"\n",
    "search = re.findall(regex, artikel)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "887500ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def smallest_chatbot_in_the_world():\n",
    "    print(\"Hi. What's up?\")\n",
    "    user_input = input(\">>> \")\n",
    "    \n",
    "    # mini chat-bot\n",
    "    regex_problem = r\"(problem|issue[s]?) with ([a-zA-Z\\s]*\\b)\"\n",
    "    problem_mentioned = re.findall(regex_problem, user_input)\n",
    "\n",
    "    if len(problem_mentioned) > 0:\n",
    "        problem = problem_mentioned[0][1]\n",
    "        problem = re.sub(r\"\\b(my|our)\\b\", \"your\", problem)\n",
    "        print(\"Come on! ... *MIMIMI* ... \")\n",
    "        time.sleep(1)\n",
    "        print(f\"Stop complaining about {problem}!!\")\n",
    "    else:\n",
    "        print(\"Yeah, I know what you mean.\")\n",
    "    time.sleep(2)\n",
    "    print(\"Let's try something better next time... gotta go.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df2d4147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. What's up?\n",
      ">>> Hi! I have a real problem with my data science course!\n",
      "Come on! ... *MIMIMI* ... \n",
      "Stop complaining about your data science course!!\n",
      "Let's try something better next time... gotta go.\n"
     ]
    }
   ],
   "source": [
    "smallest_chatbot_in_the_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d337a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. What's up?\n",
      ">>> I have serious issues with our world today.\n",
      "Come on! ... *MIMIMI* ... \n",
      "Stop complaining about your world today!!\n",
      "Let's try something better next time... gotta go.\n"
     ]
    }
   ],
   "source": [
    "smallest_chatbot_in_the_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0adef98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Hi! I have a real problem with my data science course!\n",
      "What exactly is wrong with your data science course?\n"
     ]
    }
   ],
   "source": [
    "#user_input = \"Hi there. I have a problem with my broken bike.\"\n",
    "#user_input = \"Hello... I have a real problem!\"\n",
    "#user_input = \"Hello... I have a real problem with all the violence!\"\n",
    "\n",
    "regex_problem = r\"(problem|issue) with ([a-zA-Z\\s]*\\b)\"\n",
    "problem_mentioned = re.findall(regex_problem, user_input)\n",
    "\n",
    "# mini chat-bot\n",
    "print(\">>\", user_input)\n",
    "if len(problem_mentioned) > 0:\n",
    "    problem = problem_mentioned[0][1]\n",
    "    problem = re.sub(r\"\\b(my|our)\\b\", \"your\", problem)\n",
    "    print(f\"What exactly is wrong with {problem}?\")\n",
    "else:\n",
    "    print(\"Yeah, I know what you mean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7a56eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "reflections = {\n",
    "    \"am\": \"are\",\n",
    "    \"was\": \"were\",\n",
    "    \"i\": \"you\",\n",
    "    \"i'd\": \"you would\",\n",
    "    \"i've\": \"you have\",\n",
    "    \"i'll\": \"you will\",\n",
    "    \"my\": \"your\",\n",
    "    \"are\": \"am\",\n",
    "    \"you've\": \"I have\",\n",
    "    \"you'll\": \"I will\",\n",
    "    \"your\": \"my\",\n",
    "    \"yours\": \"mine\",\n",
    "    \"you\": \"me\",\n",
    "    \"me\": \"you\"\n",
    "}\n",
    " \n",
    "psychobabble = [\n",
    "    [r'I need (.*)',\n",
    "     [\"Why do you need {0}?\",\n",
    "      \"Would it really help you to get {0}?\",\n",
    "      \"Are you sure you need {0}?\"]],\n",
    " \n",
    "    [r'Why don\\'?t you ([^\\?]*)\\??',\n",
    "     [\"Do you really think I don't {0}?\",\n",
    "      \"Perhaps eventually I will {0}.\",\n",
    "      \"Do you really want me to {0}?\"]],\n",
    " \n",
    "    [r'Why can\\'?t I ([^\\?]*)\\??',\n",
    "     [\"Do you think you should be able to {0}?\",\n",
    "      \"If you could {0}, what would you do?\",\n",
    "      \"I don't know -- why can't you {0}?\",\n",
    "      \"Have you really tried?\"]],\n",
    " \n",
    "    [r'I can\\'?t (.*)',\n",
    "     [\"How do you know you can't {0}?\",\n",
    "      \"Perhaps you could {0} if you tried.\",\n",
    "      \"What would it take for you to {0}?\"]],\n",
    " \n",
    "    [r'I am (.*)',\n",
    "     [\"Did you come to me because you are {0}?\",\n",
    "      \"How long have you been {0}?\",\n",
    "      \"How do you feel about being {0}?\"]],\n",
    "\n",
    "    [r'(.*)\\?',\n",
    "     [\"Why do you ask that?\",\n",
    "      \"Please consider whether you can answer your own question.\",\n",
    "      \"Perhaps the answer lies within yourself?\",\n",
    "      \"Why don't you tell me?\"]],\n",
    "]\n",
    "\n",
    "\n",
    "def reflect(fragment):                      #These have to be here...\n",
    "            tokens = fragment.lower().split()\n",
    "            for i, token in enumerate(tokens):\n",
    "                if token in reflections:\n",
    "                    tokens[i] = reflections[token]\n",
    "            return ' '.join(tokens)\n",
    "\n",
    "def eliza_answer(user_input):\n",
    "    for pattern, responses in psychobabble:\n",
    "        match = re.search(pattern, str(user_input))\n",
    "        if match:                                   #ELIZA Responses\n",
    "            rspns = random.choice(responses)\n",
    "            return rspns.format(*[reflect(g) for g in match.groups()])    \n",
    "    else:                                           #ChatterBot Responses\n",
    "        response = \"...\"\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "639a2496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> I am so ashamed of who I was\n",
      "How long have you been so ashamed of who you were?\n",
      ">> Its just that I can't forget about it\n",
      "How do you know you can't forget about it?\n",
      ">> How should I go on from here?\n",
      "Please consider whether you can answer your own question.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I am so ashamed of who I was\"\n",
    "print(\">>\", user_input)\n",
    "print(eliza_answer(user_input))\n",
    "\n",
    "user_input = \"Its just that I can't forget about it\"\n",
    "print(\">>\", user_input)\n",
    "print(eliza_answer(user_input))\n",
    "\n",
    "user_input = \"How should I go on from here?\"\n",
    "print(\">>\", user_input)\n",
    "print(eliza_answer(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9cc1a",
   "metadata": {},
   "source": [
    "Some eliza-like example code https://github.com/graylu21/ELIZA-ChatterBot/blob/master/ELIZAChatterBot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f091a4",
   "metadata": {},
   "source": [
    "### Developing Regex solutions\n",
    "\n",
    "Luckily, there are nice tools to help develop regular expressions more interactively. It remains a game of often tricky puzzles, but it often helps a lot to use those tools. For instance:\n",
    "- https://regex101.com/\n",
    "- https://regexr.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd592dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.dummy@something.com\n",
    "this goes to all people@all\n",
    "This-is-my-mail@my-mail.home.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621adb1f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
